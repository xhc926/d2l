{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhc926/d2l/blob/main/chapter_deep-learning-computation/read-write.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec47e64",
      "metadata": {
        "origin_pos": 0,
        "id": "bec47e64"
      },
      "source": [
        "# 读写文件\n",
        "\n",
        "到目前为止，我们讨论了如何处理数据，\n",
        "以及如何构建、训练和测试深度学习模型。\n",
        "然而，有时我们希望保存训练的模型，\n",
        "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
        "此外，当运行一个耗时较长的训练过程时，\n",
        "最佳的做法是定期保存中间结果，\n",
        "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
        "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
        "\n",
        "## (**加载和保存张量**)\n",
        "\n",
        "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
        "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9b319fd3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:42.668559Z",
          "iopub.status.busy": "2023-08-18T06:56:42.667248Z",
          "iopub.status.idle": "2023-08-18T06:56:43.728764Z",
          "shell.execute_reply": "2023-08-18T06:56:43.727885Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "9b319fd3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f44ac7",
      "metadata": {
        "origin_pos": 5,
        "id": "e4f44ac7"
      },
      "source": [
        "我们现在可以将存储在文件中的数据读回内存。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1ab53461",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.733002Z",
          "iopub.status.busy": "2023-08-18T06:56:43.732347Z",
          "iopub.status.idle": "2023-08-18T06:56:43.741208Z",
          "shell.execute_reply": "2023-08-18T06:56:43.740416Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ab53461",
        "outputId": "e9ac2edf-5a7b-48e9-9d86-560ea9fe4ca2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d4a111",
      "metadata": {
        "origin_pos": 10,
        "id": "44d4a111"
      },
      "source": [
        "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "81027fe1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.744676Z",
          "iopub.status.busy": "2023-08-18T06:56:43.744140Z",
          "iopub.status.idle": "2023-08-18T06:56:43.751376Z",
          "shell.execute_reply": "2023-08-18T06:56:43.750630Z"
        },
        "origin_pos": 12,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81027fe1",
        "outputId": "8d27a300-0777-4bba-ebda-ec0a16fbdcd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b060dd48",
      "metadata": {
        "origin_pos": 15,
        "id": "b060dd48"
      },
      "source": [
        "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
        "当我们要读取或写入模型中的所有权重时，这很方便。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fde1cb33",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.754777Z",
          "iopub.status.busy": "2023-08-18T06:56:43.754313Z",
          "iopub.status.idle": "2023-08-18T06:56:43.761150Z",
          "shell.execute_reply": "2023-08-18T06:56:43.760369Z"
        },
        "origin_pos": 17,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fde1cb33",
        "outputId": "8ee99021-b23f-49d2-92f4-5a42e403359a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa857bf",
      "metadata": {
        "origin_pos": 20,
        "id": "afa857bf"
      },
      "source": [
        "## [**加载和保存模型参数**]\n",
        "\n",
        "保存单个权重向量（或其他张量）确实有用，\n",
        "但是如果我们想保存整个模型，并在以后加载它们，\n",
        "单独保存每个向量则会变得很麻烦。\n",
        "毕竟，我们可能有数百个参数散布在各处。\n",
        "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
        "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
        "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
        "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
        "因此，为了恢复模型，我们需要用代码生成架构，\n",
        "然后从磁盘加载参数。\n",
        "让我们从熟悉的多层感知机开始尝试一下。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2672b5c2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.764609Z",
          "iopub.status.busy": "2023-08-18T06:56:43.764090Z",
          "iopub.status.idle": "2023-08-18T06:56:43.773070Z",
          "shell.execute_reply": "2023-08-18T06:56:43.772277Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "2672b5c2"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697ceed0",
      "metadata": {
        "origin_pos": 25,
        "id": "697ceed0"
      },
      "source": [
        "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a53c1315",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.776452Z",
          "iopub.status.busy": "2023-08-18T06:56:43.775942Z",
          "iopub.status.idle": "2023-08-18T06:56:43.780387Z",
          "shell.execute_reply": "2023-08-18T06:56:43.779636Z"
        },
        "origin_pos": 27,
        "tab": [
          "pytorch"
        ],
        "id": "a53c1315"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdwG2cN_X29n",
        "outputId": "2916c2f4-ef9c-4062-a8e9-cf635c39f5f9"
      },
      "id": "jdwG2cN_X29n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0748,  0.6275, -1.5608, -0.2621, -1.9998, -1.7488, -0.1968,  0.7899,\n",
              "         -0.2663, -0.4439,  1.7839,  0.1673,  0.6408,  1.8524, -0.7823, -0.1006,\n",
              "          0.4129,  0.9639,  1.7717,  0.4903],\n",
              "        [-0.9122,  1.6283,  0.0507, -0.2198,  2.2495,  0.2067, -0.3377, -1.6605,\n",
              "          1.1664, -2.3866, -0.1195,  0.0734, -0.8552, -1.0523, -0.6170,  1.0060,\n",
              "         -0.6862, -0.8982,  1.8713, -0.0296]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoV8pEzQX4dX",
        "outputId": "7039816c-91a3-4d79-8672-05f4242f9098"
      },
      "id": "BoV8pEzQX4dX",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0588, -0.5390,  0.2971,  0.0263, -0.0512,  0.0243, -0.4967, -0.2068,\n",
              "         -0.0290,  0.1225],\n",
              "        [-0.4666,  0.0204,  0.3754,  0.0464, -0.2590,  0.1380, -0.2410,  0.0722,\n",
              "         -0.4441,  0.4980]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6df754a",
      "metadata": {
        "origin_pos": 30,
        "id": "b6df754a"
      },
      "source": [
        "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
        "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "da5e1b3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.783850Z",
          "iopub.status.busy": "2023-08-18T06:56:43.783240Z",
          "iopub.status.idle": "2023-08-18T06:56:43.789905Z",
          "shell.execute_reply": "2023-08-18T06:56:43.789164Z"
        },
        "origin_pos": 32,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5e1b3f",
        "outputId": "c0b37a69-59cf-4dda-942e-573b68abfa40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65076662",
      "metadata": {
        "origin_pos": 35,
        "id": "65076662"
      },
      "source": [
        "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
        "两个实例的计算结果应该相同。\n",
        "让我们来验证一下。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a25ba1f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:56:43.793400Z",
          "iopub.status.busy": "2023-08-18T06:56:43.792788Z",
          "iopub.status.idle": "2023-08-18T06:56:43.798329Z",
          "shell.execute_reply": "2023-08-18T06:56:43.797576Z"
        },
        "origin_pos": 37,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25ba1f1",
        "outputId": "7a156dce-3c5e-4e29-a558-4ee00cbcd5d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone"
      ],
      "metadata": {
        "id": "4C2MwWZ5YNrP",
        "outputId": "83bd3326-e8d3-45a2-d1c3-91de791a8ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4C2MwWZ5YNrP",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0588, -0.5390,  0.2971,  0.0263, -0.0512,  0.0243, -0.4967, -0.2068,\n",
              "         -0.0290,  0.1225],\n",
              "        [-0.4666,  0.0204,  0.3754,  0.0464, -0.2590,  0.1380, -0.2410,  0.0722,\n",
              "         -0.4441,  0.4980]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a65b1e2",
      "metadata": {
        "origin_pos": 39,
        "id": "7a65b1e2"
      },
      "source": [
        "## 小结\n",
        "\n",
        "* `save`和`load`函数可用于张量对象的文件读写。\n",
        "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
        "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
        "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
        "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d803f301",
      "metadata": {
        "origin_pos": 41,
        "tab": [
          "pytorch"
        ],
        "id": "d803f301"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1839)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}